{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gensim intro.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "zKR8JSyB3Hgq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1: Corpora and Vector Spaces"
      ]
    },
    {
      "metadata": {
        "id": "lqEVV4h93Hgu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycSpOIxJ3Hg0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0eb9b56a-d2c4-4299-e93e-20b46b703f2f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106167996,
          "user_tz": -330,
          "elapsed": 810,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "TEMP_FOLDER = tempfile.gettempdir()\n",
        "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder \"/tmp\" will be used to save temporary dictionary and corpus.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dz8XByNb3Hg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "to see logging events.\n",
        "\n",
        "## From Strings to Vectors\n",
        "\n",
        "start from documents represented as strings:"
      ]
    },
    {
      "metadata": {
        "id": "AmepOcCb3U79",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "6f8d79fc-92b1-485c-e551-e2cefc4b2ab3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106178715,
          "user_tz": -330,
          "elapsed": 10637,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/57/dc00a059b1b739c71dd25355541ebe141ce1ba31917671c826c5fcdfd145/gensim-3.4.0-cp27-cp27mu-manylinux1_x86_64.whl (22.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 22.6MB 1.2MB/s \n",
            "\u001b[?25hCollecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/69/c92661a333f733510628f28b8282698b62cdead37291c8491f3271677c02/smart_open-1.5.7.tar.gz\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python2.7/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python2.7/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python2.7/dist-packages (from gensim) (1.14.3)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 10.2MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/96/af0ef85424ce21fb2dbdd4dae0754853f9327304d8562c6d2eaffd2654ca/boto3-1.7.19-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.11.0,>=1.10.19 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/05/1ffe77f2b8fb03a9223f3d0743cd38cded9491b074c65f3bb664ed4b7ac6/botocore-1.10.19-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.2MB 4.8MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 14.5MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.11.0,>=1.10.19->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/c53398e0005b11f7ffb27b7aa720c617aba53be4fb4f4f3f06b9b5c60f28/docutils-0.14-py2-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python2.7/dist-packages (from botocore<1.11.0,>=1.10.19->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: futures<4.0.0,>=2.2.0; python_version == \"2.6\" or python_version == \"2.7\" in /usr/local/lib/python2.7/dist-packages (from s3transfer<0.2.0,>=0.1.10->boto3->smart-open>=1.2.1->gensim) (3.2.0)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b1/9e/7d/bb3d3b55c597e72617140a0638c06382a5f17283881eae163e\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.48.0 boto3-1.7.19 botocore-1.10.19 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uDBYY-XN3Hg6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dc72764-e332-4deb-ee5c-f5c5ac400a34",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106179657,
          "user_tz": -330,
          "elapsed": 922,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim import corpora"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:08,578 : INFO : 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ksiC3j03Hg-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "documents = [\"Human machine interface for lab abc computer applications\",\n",
        "             \"A survey of user opinion of computer system response time\",\n",
        "             \"The EPS user interface management system\",\n",
        "             \"System and human system engineering testing of EPS\",              \n",
        "             \"Relation of user perceived response time to error measurement\",\n",
        "             \"The generation of random binary unordered trees\",\n",
        "             \"The intersection graph of paths in trees\",\n",
        "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "             \"Graph minors A survey\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hvj3gSQJ3HhF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a tiny corpus of nine documents, each consisting of only a single sentence. (array...)\n",
        "\n",
        "BUT First,  tokenize the documents, remove common words (using a toy stoplist)   Stom list is a fancy way of saying stuff we want to remove... from the corpus\n",
        "\n",
        "as well as words that only appear once in the corpus:"
      ]
    },
    {
      "metadata": {
        "id": "ThqTHMNr3HhH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d53948eb-7fb1-4588-da07-345e56246019",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106181546,
          "user_tz": -330,
          "elapsed": 918,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# remove common words and tokenize\n",
        "stoplist = set('for a of the and to in'.split())\n",
        "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in documents]\n",
        "\n",
        "# remove words that appear only once\n",
        "from collections import defaultdict # fancy high performance data structure\n",
        "frequency = defaultdict(int)\n",
        "for text in texts:\n",
        "    for token in text:\n",
        "        frequency[token] += 1\n",
        "\n",
        "texts = [[token for token in text if frequency[token] > 1] for text in texts] # cool list comprehencsion again :)\n",
        "\n",
        "from pprint import pprint  # pretty-printer\n",
        "pprint(texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['human', 'interface', 'computer'],\n",
            " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
            " ['eps', 'user', 'interface', 'system'],\n",
            " ['system', 'human', 'system', 'eps'],\n",
            " ['user', 'response', 'time'],\n",
            " ['trees'],\n",
            " ['graph', 'trees'],\n",
            " ['graph', 'minors', 'trees'],\n",
            " ['graph', 'minors', 'survey']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b_nn6WWP3HhT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Your way of processing the documents will likely vary; here, I only split on whitespace to tokenize, followed by lowercasing each word. In fact, I use this particular (simplistic and inefficient) setup to mimic the experiment done in [Deerwester et al.’s original LSA article](http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf) (Table 2).\n",
        "\n",
        "The ways to process documents are so varied and application- and language-dependent that I decided to not constrain them by any interface. Instead, a document is represented by the features extracted from it, not by its “surface” string form: how you get to the features is up to you. Below I describe one common, general-purpose approach (called bag-of-words), but keep in mind that different application domains call for different features, and, as always, it’s [garbage in, garbage out](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out)...\n",
        "\n",
        "To convert documents to vectors, we’ll use a document representation called [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model). In this representation, each document is represented by one vector where a vector element `i` represents the number of times the `i`th word appears in the document.\n",
        "\n",
        "It is advantageous to represent the questions only by their (integer) ids. The mapping between the questions and ids is called a dictionary:"
      ]
    },
    {
      "metadata": {
        "id": "QAm_DTds3HhW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "679ed573-cddb-4d03-ba84-291ba7a74fe7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106182485,
          "user_tz": -330,
          "elapsed": 863,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(texts)\n",
        "dictionary.save(os.path.join(TEMP_FOLDER, 'deerwester.dict'))  # store the dictionary, for future reference\n",
        "print(dictionary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:11,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2018-05-12 06:23:11,169 : INFO : built Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...) from 9 documents (total 29 corpus positions)\n",
            "2018-05-12 06:23:11,174 : INFO : saving Dictionary object under /tmp/deerwester.dict, separately None\n",
            "2018-05-12 06:23:11,177 : INFO : saved /tmp/deerwester.dict\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Vqve8VS3Hhe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we assigned a unique integer ID to all words appearing in the processed corpus with the [gensim.corpora.dictionary.Dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary) class. This sweeps across the texts, collecting word counts and relevant statistics. In the end, we see there are twelve distinct words in the processed corpus, which means each document will be represented by twelve numbers (ie., by a 12-D vector). To see the mapping between words and their ids:"
      ]
    },
    {
      "metadata": {
        "id": "PBG5kUl43Hhg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef361796-ac48-4be0-9b55-f0d9f7ae2f28",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106183426,
          "user_tz": -330,
          "elapsed": 857,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(dictionary.token2id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{u'minors': 11, u'graph': 10, u'system': 5, u'trees': 9, u'eps': 8, u'computer': 0, u'survey': 4, u'user': 7, u'human': 1, u'time': 6, u'interface': 2, u'response': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8XtRUa6h3Hhr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To actually convert tokenized documents to vectors:"
      ]
    },
    {
      "metadata": {
        "id": "NrkRmoDV3Hht",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6bfd643-74b3-4a90-a9fb-fa9abea7de7e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106184420,
          "user_tz": -330,
          "elapsed": 919,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "new_doc = \"Human human computer interaction system\"\n",
        "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
        "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 2), (5, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pH0u5DJ73Hhz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function `doc2bow()` simply counts the number of occurrences of each distinct word,   \n",
        "converts the word to its integer word id and returns the result as a bag-of-words--a sparse vector, in the form of  \n",
        "`[(word_id, word_count), ...]`. \n",
        "\n",
        "As the token_id is 0 for *\"human\"* and 2 for *\"computer\"*,   \n",
        "the new document *“Human computer interaction”* will be transformed to  \n",
        "[(0, 1), (2, 1)].   \n",
        "\n",
        "*actually 1 is for human and 0 for computer in this run of the code..* not sure y  \n",
        "\n",
        "The words *\"computer\"* and *\"system\"* exist in the dictionary and appear once. Thus, they become (0, 1),  (5, 1)respectively in the sparse vector.   \n",
        "\n",
        "we added another human just to confrimt he mapping as seen above \n",
        "\n",
        "\n",
        "The word *\"interaction\"* doesn't exist in the dictionary and, thus, will not show up in the sparse vector. The other ten dictionary words, that appear (implicitly) zero times, will not show up in the sparse vector and , ,there will never be a element in the sparse vector like (3, 0).\n",
        "\n",
        "For people familiar with scikit learn, `doc2bow()` has similar behaviors as calling `transform()` on [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). `doc2bow()` can behave like `fit_transform()` as well. For more details, please look at [gensim API Doc](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2bow)."
      ]
    },
    {
      "metadata": {
        "id": "9Dl7QWmQ3Hh0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "8090824b-701c-4b4c-e38f-2e77b42f410b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106185354,
          "user_tz": -330,
          "elapsed": 842,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'deerwester.mm'), corpus)  # store to disk, for later use\n",
        "for c in corpus:\n",
        "    print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:14,025 : INFO : storing corpus in Matrix Market format to /tmp/deerwester.mm\n",
            "2018-05-12 06:23:14,028 : INFO : saving sparse matrix to /tmp/deerwester.mm\n",
            "2018-05-12 06:23:14,033 : INFO : PROGRESS: saving document #0\n",
            "2018-05-12 06:23:14,039 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
            "2018-05-12 06:23:14,040 : INFO : saving MmCorpus index to /tmp/deerwester.mm.index\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1)]\n",
            "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
            "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
            "[(1, 1), (5, 2), (8, 1)]\n",
            "[(3, 1), (6, 1), (7, 1)]\n",
            "[(9, 1)]\n",
            "[(9, 1), (10, 1)]\n",
            "[(9, 1), (10, 1), (11, 1)]\n",
            "[(4, 1), (10, 1), (11, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0xfpCljs3HiN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By now it should be clear that the vector feature with `id=10` represents the number of times the word \"graph\" occurs in the document.  The answer is “zero” for the first six documents and “one” for the remaining three. As a matter of fact, we have arrived at exactly the same corpus of vectors as in the [Quick Example](https://radimrehurek.com/gensim/tutorial.html#first-example). If you're running this notebook yourself the word IDs may differ, but you should be able to check the consistency between documents comparing their vectors. \n",
        "\n",
        "## Corpus Streaming – One Document at a Time\n",
        "\n",
        "Note that *corpus* above resides fully in memory, as a plain Python list. In this simple example, it doesn’t matter much, but just to make things clear, let’s assume there are millions of documents in the corpus.   \n",
        "Storing all of them in RAM won’t do. Instead, let’s assume the documents are stored in a file on disk, one document per line. Gensim only requires that a corpus be able to return one document (the document mentioned just now being one line in the actual document)vector at a time:"
      ]
    },
    {
      "metadata": {
        "id": "u8fYJrJP9ozT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2298741-f128-4ec6-f91f-74cf4f90e7ec",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106188273,
          "user_tz": -330,
          "elapsed": 2863,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#when you get lazy to upload a file you do all kinds of jugaad\n",
        "! pip install numpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (1.14.3)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UQ1zevIa9u1_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#! touch datasets/mycorpus.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TS8G6R8_91fC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.savetxt('mycorpus.txt', documents,  fmt=\"%s\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGQGWyPj3HiT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from smart_open import smart_open\n",
        "class MyCorpus(object):\n",
        "    def __iter__(self):\n",
        "        for line in smart_open('mycorpus.txt', 'rb'):\n",
        "            # assume there's one document per line, tokens separated by whitespace\n",
        "            yield dictionary.doc2bow(line.lower().split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tg0LrrBI3Hif",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The assumption that each document occupies one line in a single file is not important; you can design the `__iter__` function to fit your input format, whatever that may be - walking directories, parsing XML, accessing network nodes... Just parse your input to retrieve a clean list of tokens in each document, then convert the tokens via a dictionary to their IDs and yield the resulting sparse vector inside `__iter__`."
      ]
    },
    {
      "metadata": {
        "id": "B8klFR433Hif",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f625797b-c5e7-42bd-a778-98f7617e86ac",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106192299,
          "user_tz": -330,
          "elapsed": 957,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "corpus_memory_friendly = MyCorpus() # doesn't load the corpus into memory!\n",
        "print(corpus_memory_friendly)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.MyCorpus object at 0x7ffad463cdd0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "beqokrkG3Hio",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`corpus_memory_friendly` is now an object. We didn’t define any way to print it, so `print` just outputs address of the object in memory. Not very useful. To see the constituent vectors, let’s iterate over the corpus and print each document vector (one at a time):"
      ]
    },
    {
      "metadata": {
        "id": "B3RfPIFb3Hio",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "acd67cd9-7826-48a7-ab7c-2545c7bd1f1b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106193371,
          "user_tz": -330,
          "elapsed": 927,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for vector in corpus_memory_friendly:  # load one vector into memory at a time\n",
        "    print(vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (2, 1)]\n",
            "[(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
            "[(2, 1), (5, 1), (7, 1), (8, 1)]\n",
            "[(1, 1), (5, 2), (8, 1)]\n",
            "[(3, 1), (6, 1), (7, 1)]\n",
            "[(9, 1)]\n",
            "[(9, 1), (10, 1)]\n",
            "[(9, 1), (10, 1), (11, 1)]\n",
            "[(4, 1), (10, 1), (11, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fdm0_6mg3Hit",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Although the output is the same as for the plain Python list, the corpus is now much more memory friendly, because at most one vector resides in RAM at a time. Your corpus can now be as large as you want.\n",
        "\n",
        "We are going to create the dictionary from the mycorpus.txt file without loading the entire file into memory.   \n",
        "Then, we will generate the list of token ids to remove from this dictionary by querying the dictionary for the token ids of the stop words,   \n",
        "and by querying the document frequencies dictionary (`dictionary.dfs`) for token ids that only appear once.  \n",
        "\n",
        "Finally, we will filter these token ids out of our dictionary.   \n",
        "Keep in mind that `dictionary.filter_tokens` (and some other functions such as `dictionary.add_document`)   \n",
        "will call `dictionary.compactify()` to remove the gaps in the token id series thus enumeration of remaining tokens can be changed.\n"
      ]
    },
    {
      "metadata": {
        "id": "-5fLgRxF3Hiu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6203f90f-d0b7-4df2-e99d-4f82a824dc84",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106194541,
          "user_tz": -330,
          "elapsed": 1104,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from six import iteritems\n",
        "from smart_open import smart_open\n",
        "\n",
        "# collect statistics about all tokens\n",
        "dictionary = corpora.Dictionary(line.lower().split() for line in smart_open('mycorpus.txt', 'rb'))\n",
        "\n",
        "# remove stop words and words that appear only once\n",
        "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist \n",
        "            if stopword in dictionary.token2id]\n",
        "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
        "\n",
        "# remove stop words and words that appear only once\n",
        "dictionary.filter_tokens(stop_ids + once_ids)\n",
        "print(dictionary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:23,007 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2018-05-12 06:23:23,014 : INFO : built Dictionary(42 unique tokens: [u'and', u'minors', u'generation', u'testing', u'iv']...) from 9 documents (total 69 corpus positions)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o4C8WDyy3Hiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And that is all there is to it! At least as far as bag-of-words representation is concerned. Of course, what we do with such a corpus is another question; it is not at all clear how counting the frequency of distinct words could be useful. As it turns out, it isn’t, and we will need to apply a transformation on this simple representation first, before we can use it to compute any meaningful document vs. document similarities. Transformations are covered in the [next tutorial](https://radimrehurek.com/gensim/tut2.html), but before that, let’s briefly turn our attention to *corpus persistency*.\n",
        "\n",
        "## Corpus Formats\n",
        "\n",
        "There exist several file formats for serializing a Vector Space corpus (~sequence of vectors) to disk. *Gensim* implements them via the *streaming corpus interface* mentioned earlier: documents are read from (or stored to) disk in a lazy fashion, one document at a time, without the whole corpus being read into main memory at once.\n",
        "\n",
        "One of the more notable file formats is the [Matrix Market format](http://math.nist.gov/MatrixMarket/formats.html). To save a corpus in the Matrix Market format:"
      ]
    },
    {
      "metadata": {
        "id": "UJDCCSyl3Hiy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "4e0092ec-a1df-42ac-f52e-05da6e9b1544",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106195634,
          "user_tz": -330,
          "elapsed": 990,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# create a toy corpus of 2 documents, as a plain Python list\n",
        "corpus = [[(1, 0.5)], []]  # make one document empty, for the heck of it\n",
        "\n",
        "corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER, 'corpus.mm'), corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:24,155 : INFO : storing corpus in Matrix Market format to /tmp/corpus.mm\n",
            "2018-05-12 06:23:24,158 : INFO : saving sparse matrix to /tmp/corpus.mm\n",
            "2018-05-12 06:23:24,162 : INFO : PROGRESS: saving document #0\n",
            "2018-05-12 06:23:24,164 : INFO : saved 2x2 matrix, density=25.000% (1/4)\n",
            "2018-05-12 06:23:24,166 : INFO : saving MmCorpus index to /tmp/corpus.mm.index\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KeSioPSj3Hi3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Other formats include [Joachim’s SVMlight format](http://svmlight.joachims.org/), [Blei’s LDA-C format](http://www.cs.columbia.edu/~blei/lda-c/) and [GibbsLDA++ format](http://gibbslda.sourceforge.net/)."
      ]
    },
    {
      "metadata": {
        "id": "PXcUnIaz3Hi5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "3aa5ed06-a779-41de-cd2b-09c49af53069",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106196735,
          "user_tz": -330,
          "elapsed": 973,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "corpora.SvmLightCorpus.serialize(os.path.join(TEMP_FOLDER, 'corpus.svmlight'), corpus)\n",
        "corpora.BleiCorpus.serialize(os.path.join(TEMP_FOLDER, 'corpus.lda-c'), corpus)\n",
        "corpora.LowCorpus.serialize(os.path.join(TEMP_FOLDER, 'corpus.low'), corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:25,253 : INFO : converting corpus to SVMlight format: /tmp/corpus.svmlight\n",
            "2018-05-12 06:23:25,255 : INFO : saving SvmLightCorpus index to /tmp/corpus.svmlight.index\n",
            "2018-05-12 06:23:25,258 : INFO : no word id mapping provided; initializing from corpus\n",
            "2018-05-12 06:23:25,260 : INFO : storing corpus in Blei's LDA-C format into /tmp/corpus.lda-c\n",
            "2018-05-12 06:23:25,262 : INFO : saving vocabulary of 2 words to /tmp/corpus.lda-c.vocab\n",
            "2018-05-12 06:23:25,264 : INFO : saving BleiCorpus index to /tmp/corpus.lda-c.index\n",
            "2018-05-12 06:23:25,266 : INFO : no word id mapping provided; initializing from corpus\n",
            "2018-05-12 06:23:25,267 : INFO : storing corpus in List-Of-Words format into /tmp/corpus.low\n",
            "2018-05-12 06:23:25,269 : WARNING : List-of-words format can only save vectors with integer elements; 1 float entries were truncated to integer value\n",
            "2018-05-12 06:23:25,273 : INFO : saving LowCorpus index to /tmp/corpus.low.index\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aWUE6aKw3Hi8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conversely, to load a corpus iterator from a Matrix Market file:"
      ]
    },
    {
      "metadata": {
        "id": "x5pAmMI93Hi9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e4e12ca5-5b71-4e0c-b664-5d36850820f2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106197745,
          "user_tz": -330,
          "elapsed": 848,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "corpus = corpora.MmCorpus(os.path.join(TEMP_FOLDER, 'corpus.mm'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:26,359 : INFO : loaded corpus index from /tmp/corpus.mm.index\n",
            "2018-05-12 06:23:26,362 : INFO : initializing cython corpus reader from /tmp/corpus.mm\n",
            "2018-05-12 06:23:26,365 : INFO : accepted corpus with 2 documents, 2 features, 1 non-zero entries\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wQZ7xCNv3HjB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Corpus objects are streams, so typically you won’t be able to print them directly:"
      ]
    },
    {
      "metadata": {
        "id": "ZOS2VZJj3HjC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0579ac2-8544-48e0-e657-2cbb61e26bb7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106198756,
          "user_tz": -330,
          "elapsed": 938,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MmCorpus(2 documents, 2 features, 1 non-zero entries)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cxTH-ULS3HjG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Instead, to view the contents of a corpus:"
      ]
    },
    {
      "metadata": {
        "id": "vPnfvCgR3HjH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "384677d3-8ecd-4fa0-f273-aeacf472fee8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106199802,
          "user_tz": -330,
          "elapsed": 936,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# one way of printing a corpus: load it entirely into memory\n",
        "print(list(corpus))  # calling list() will convert any sequence to a plain Python list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(1, 0.5)], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_NqmnA1x3HjM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "or"
      ]
    },
    {
      "metadata": {
        "id": "SuuurpmO3HjO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "664de299-4e97-4628-c614-d12be7ed76be",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106200861,
          "user_tz": -330,
          "elapsed": 989,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# another way of doing it: print one document at a time, making use of the streaming interface\n",
        "for doc in corpus:\n",
        "    print(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 0.5)]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y-8XySAk3HjX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The second way is obviously more memory-friendly, but for testing and development purposes, nothing beats the simplicity of calling `list(corpus)`.\n",
        "\n",
        "To save the same Matrix Market document stream in Blei’s LDA-C format,"
      ]
    },
    {
      "metadata": {
        "id": "ILYleEnc3HjY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "b1749433-e612-41ff-ef8d-14beda540b68",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106201981,
          "user_tz": -330,
          "elapsed": 1013,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "corpora.BleiCorpus.serialize(os.path.join(TEMP_FOLDER, 'corpus.lda-c'), corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:23:30,510 : INFO : no word id mapping provided; initializing from corpus\n",
            "2018-05-12 06:23:30,512 : INFO : storing corpus in Blei's LDA-C format into /tmp/corpus.lda-c\n",
            "2018-05-12 06:23:30,513 : INFO : saving vocabulary of 2 words to /tmp/corpus.lda-c.vocab\n",
            "2018-05-12 06:23:30,515 : INFO : saving BleiCorpus index to /tmp/corpus.lda-c.index\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IP-d4Jkj3Hjk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this way, *gensim* can also be used as a memory-efficient **I/O format conversion tool**: just load a document stream using one format and immediately save it in another format. Adding new formats is dead easy, check out the [code for the SVMlight corpus](https://github.com/piskvorky/gensim/blob/develop/gensim/corpora/svmlightcorpus.py) for an example.\n",
        "\n",
        "## Compatibility with NumPy and SciPy\n",
        "\n",
        "Gensim also contains [efficient utility functions](http://radimrehurek.com/gensim/matutils.html) to help converting from/to `numpy` matrices:"
      ]
    },
    {
      "metadata": {
        "id": "7hkIOjqi3Hjq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "60e01eee-3ad9-43f1-dd4a-3d769af1661f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106202979,
          "user_tz": -330,
          "elapsed": 902,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "numpy_matrix = np.random.randint(10, size=[5,2])\n",
        "corpus = gensim.matutils.Dense2Corpus(numpy_matrix)\n",
        "numpy_matrix_dense = gensim.matutils.corpus2dense(corpus, num_terms=10)\n",
        "\n",
        "numpy_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1],\n",
              "       [2, 1],\n",
              "       [0, 1],\n",
              "       [9, 0],\n",
              "       [5, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "aJBTcuKx3Hju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "and from/to `scipy.sparse` matrices:"
      ]
    },
    {
      "metadata": {
        "id": "BsZzFMts3Hjv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "998cf797-2807-4660-edf4-493537361a15",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106203983,
          "user_tz": -330,
          "elapsed": 908,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import scipy.sparse\n",
        "scipy_sparse_matrix = scipy.sparse.random(5,2)\n",
        "corpus = gensim.matutils.Sparse2Corpus(scipy_sparse_matrix)\n",
        "scipy_csc_matrix = gensim.matutils.corpus2csc(corpus)\n",
        "\n",
        "scipy_sparse_matrix.todense()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "_rT24C_U3Hjz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For a complete reference (want to prune the dictionary to a smaller size? Optimize converting between corpora and NumPy/SciPy arrays?), see the [API documentation](https://radimrehurek.com/gensim/apiref.html). Or continue to the next tutorial on Topics and Transformations ([notebook](Topics_and_Transformations.ipynb) \n",
        "or [website](https://radimrehurek.com/gensim/tut2.html))."
      ]
    }
  ]
}
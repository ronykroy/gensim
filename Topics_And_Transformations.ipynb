{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topics And Transformations.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "p1kdSH9dJljf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Topics and Transformation"
      ]
    },
    {
      "metadata": {
        "id": "Cfrv2MDGJljh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVxKwbE2Jljj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96ee9b73-b927-4118-a75b-e5709d4dc67f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106241015,
          "user_tz": -330,
          "elapsed": 752,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os.path\n",
        "\n",
        "TEMP_FOLDER = tempfile.gettempdir()\n",
        "print('Folder \"{}\" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder \"/tmp\" will be used to save temporary dictionary and corpus.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HAq4OduYJljp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Transformation interface\n",
        "\n",
        "Use same corpus as in the prev tute"
      ]
    },
    {
      "metadata": {
        "id": "D_C8XBOPJ4F-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "2a433f40-9300-4bf7-8e56-5b0b854c152f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106256909,
          "user_tz": -330,
          "elapsed": 12098,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\r\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 22.6MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Using cached https://files.pythonhosted.org/packages/4b/69/c92661a333f733510628f28b8282698b62cdead37291c8491f3271677c02/smart_open-1.5.7.tar.gz\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.3)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Using cached https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl\n",
            "Collecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Using cached https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Using cached https://files.pythonhosted.org/packages/9a/96/af0ef85424ce21fb2dbdd4dae0754853f9327304d8562c6d2eaffd2654ca/boto3-1.7.19-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Using cached https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl\n",
            "Collecting botocore<1.11.0,>=1.10.19 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Using cached https://files.pythonhosted.org/packages/34/05/1ffe77f2b8fb03a9223f3d0743cd38cded9491b074c65f3bb664ed4b7ac6/botocore-1.10.19-py2.py3-none-any.whl\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "  Using cached https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting docutils>=0.10 (from botocore<1.11.0,>=1.10.19->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 21.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.19->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b1/9e/7d/bb3d3b55c597e72617140a0638c06382a5f17283881eae163e\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.48.0 boto3-1.7.19 botocore-1.10.19 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bKFmm2gTCn5s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1129
        },
        "outputId": "21d01817-99fa-49f9-9d41-a9a7043792fa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106636589,
          "user_tz": -330,
          "elapsed": 44738,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install git+git://github.com/pattern3/pattern.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pattern3/pattern.git\r\n",
            "  Cloning git://github.com/pattern3/pattern.git to /tmp/pip-req-build-7s5pqbll\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from pattern==2.6) (4.6.0)\n",
            "Collecting cherrypy (from pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/01/39863c9862ebe1a64ff9e1efcc93d610e0024d5f31b6300222d8763dc9a7/CherryPy-15.0.0-py2.py3-none-any.whl (427kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 5.7MB/s \n",
            "\u001b[?25hCollecting docx (from pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/8e/5a01644697b03016de339ef444cfff28367f92984dc74eddaab1ed60eada/docx-0.2.4.tar.gz (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hCollecting feedparser (from pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K    100% |████████████████████████████████| 194kB 5.8MB/s \n",
            "\u001b[?25hCollecting pdfminer3k (from pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/87/cee0aa24f95c287020df7e3936cb51d32b34b05b430759bac15f89ea5ac2/pdfminer3k-1.3.1.tar.gz (4.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.1MB 4.6MB/s \n",
            "\u001b[?25hCollecting simplejson (from pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/ca/8776e0c494b7f16f98a4f40f1540ed6f7467f75280631d837e9cf3e5796e/simplejson-3.14.0.tar.gz (80kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from cherrypy->pattern==2.6) (1.11.0)\n",
            "Collecting portend>=2.1.1 (from cherrypy->pattern==2.6)\n",
            "  Downloading https://files.pythonhosted.org/packages/16/20/d98f22a2a5b1d7f5ab3a38154f7a1dd87846f2c5881f4b6929bdd1624e72/portend-2.2-py2.py3-none-any.whl\n",
            "Collecting cheroot>=6.2.4 (from cherrypy->pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/2d/2adc51ca551c1a404dadf49b60c9027d950967f4dc598804aba1ef30461e/cheroot-6.2.4-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 17.9MB/s \n",
            "\u001b[?25hCollecting lxml (from docx->pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/b9/ccf46cea0f698b40bca2a9c1a44039c336fe1988b82de4f7353be7a8396a/lxml-4.2.1-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.6/dist-packages (from docx->pattern==2.6) (4.0.0)\n",
            "Collecting pytest>=2.0 (from pdfminer3k->pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/52/fc48d02492d9e6070cb672d9133382e83084f567f88eff1c27bd2c6c27a8/pytest-3.5.1-py2.py3-none-any.whl (192kB)\n",
            "\u001b[K    100% |████████████████████████████████| 194kB 23.7MB/s \n",
            "\u001b[?25hCollecting ply>=3.4 (from pdfminer3k->pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 16.9MB/s \n",
            "\u001b[?25hCollecting tempora>=1.8 (from portend>=2.1.1->cherrypy->pattern==2.6)\n",
            "  Downloading https://files.pythonhosted.org/packages/55/f4/6909c23d920192dc9d2bb0d0841abb561f58fb6c816cf593a35dda0a800c/tempora-1.11-py2.py3-none-any.whl\n",
            "Collecting more-itertools>=2.6 (from cheroot>=6.2.4->cherrypy->pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/46/886917c6a4ce49dd3fff250c01c5abac5390d57992751384fe61befc4877/more_itertools-4.1.0-py3-none-any.whl (47kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 13.8MB/s \n",
            "\u001b[?25hCollecting backports.functools-lru-cache (from cheroot>=6.2.4->cherrypy->pattern==2.6)\n",
            "  Downloading https://files.pythonhosted.org/packages/03/8e/2424c0e65c4a066e28f539364deee49b6451f8fcd4f718fefa50cc3dcf48/backports.functools_lru_cache-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=2.0->docx->pattern==2.6) (0.45.1)\n",
            "Collecting py>=1.5.0 (from pytest>=2.0->pdfminer3k->pattern==2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/a5/f77982214dd4c8fd104b066f249adea2c49e25e8703d284382eb5e9ab35a/py-1.5.3-py2.py3-none-any.whl (84kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 21.2MB/s \n",
            "\u001b[?25hCollecting pluggy<0.7,>=0.5 (from pytest>=2.0->pdfminer3k->pattern==2.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  Downloading https://files.pythonhosted.org/packages/ba/65/ded3bc40bbf8d887f262f150fbe1ae6637765b5c9534bd55690ed2c0b0f7/pluggy-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=2.0->pdfminer3k->pattern==2.6) (39.1.0)\n",
            "Collecting attrs>=17.4.0 (from pytest>=2.0->pdfminer3k->pattern==2.6)\n",
            "  Downloading https://files.pythonhosted.org/packages/41/59/cedf87e91ed541be7957c501a92102f9cc6363c623a7666d69d51c78ac5b/attrs-18.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern==2.6) (2018.4)\n",
            "Building wheels for collected packages: pattern, docx, feedparser, pdfminer3k, simplejson\n",
            "  Running setup.py bdist_wheel for pattern ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-qnafz_d7/wheels/42/86/32/4c2c2365f5f4247ff44ae48bb2290f4fb024b2d2a48bf52a32\n",
            "  Running setup.py bdist_wheel for docx ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/cc/8d/09/563edfd874a35c0c7ed129b6c4fa890efa4c26458bdec6ffc1\n",
            "  Running setup.py bdist_wheel for feedparser ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "  Running setup.py bdist_wheel for pdfminer3k ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/ca/4f/a7/cb601b4fb257d2321ac668b7c6e269176780bd0283eda855d2\n",
            "  Running setup.py bdist_wheel for simplejson ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/a5/b2/88/3717830e4e740e022d850d2e8d646789a2455472574736047c\n",
            "Successfully built pattern docx feedparser pdfminer3k simplejson\n",
            "Installing collected packages: tempora, portend, more-itertools, backports.functools-lru-cache, cheroot, cherrypy, lxml, docx, feedparser, py, pluggy, attrs, pytest, ply, pdfminer3k, simplejson, pattern\n",
            "Successfully installed attrs-18.1.0 backports.functools-lru-cache-1.5 cheroot-6.2.4 cherrypy-15.0.0 docx-0.2.4 feedparser-5.2.1 lxml-4.2.1 more-itertools-4.1.0 pattern-2.6 pdfminer3k-1.3.1 pluggy-0.6.0 ply-3.11 portend-2.2 py-1.5.3 pytest-3.5.1 simplejson-3.14.0 tempora-1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mFXNMT5cJljr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5c4b701b-0af2-484c-9a4a-9f72148fa996",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106650001,
          "user_tz": -330,
          "elapsed": 965,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models, similarities\n",
        "if os.path.isfile(os.path.join(TEMP_FOLDER, 'deerwester.dict')):\n",
        "    dictionary = corpora.Dictionary.load(os.path.join(TEMP_FOLDER, 'deerwester.dict'))\n",
        "    corpus = corpora.MmCorpus(os.path.join(TEMP_FOLDER, 'deerwester.mm'))\n",
        "    print(\"Used files generated from first tutorial\")\n",
        "else:\n",
        "    print(\"Please run first tutorial to generate data set\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:30:58,647 : INFO : loading Dictionary object from /tmp/deerwester.dict\n",
            "2018-05-12 06:30:58,649 : INFO : loaded /tmp/deerwester.dict\n",
            "2018-05-12 06:30:58,651 : INFO : loaded corpus index from /tmp/deerwester.mm.index\n",
            "2018-05-12 06:30:58,652 : INFO : initializing cython corpus reader from /tmp/deerwester.mm\n",
            "2018-05-12 06:30:58,654 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Used files generated from first tutorial\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jx2LXvvwB5dZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2018-05-12 06:24:40,848 : INFO : 'pattern' package not found; tag filters are not available for English  \n",
        "Got the above error...   \n",
        "\n",
        "resolved with the git command found at...  \n",
        "\n",
        "https://groups.google.com/forum/#!searchin/gensim/pattern%7Csort:relevance/gensim/a4HxyUCFddE/Bbv-pjb-AwAJ\n"
      ]
    },
    {
      "metadata": {
        "id": "ktBcvLX4Jljt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "23778d08-e3aa-41b7-b513-3331be1889c0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106686649,
          "user_tz": -330,
          "elapsed": 925,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(dictionary[0])\n",
        "print(dictionary[1])\n",
        "print(dictionary[2])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "computer\n",
            "human\n",
            "interface\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5mUfYHwrJljw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this tutorial, see how to transform documents from one vector representation into another. This process serves two goals:\n",
        "\n",
        "1. To bring out hidden structure in the corpus, discover relationships between words and use them to describe the documents in a new and (hopefully) more semantic way.\n",
        "1. To make the document representation more compact. This both improves efficiency (new representation consumes less resources) and efficacy (marginal data trends are ignored, noise-reduction).\n",
        "\n",
        "### Creating a transformation\n",
        "\n",
        "The transformations are standard Python objects, typically initialized by means of a training corpus:"
      ]
    },
    {
      "metadata": {
        "id": "a0--A_TLJljx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9268e6d1-c881-4e81-ac8b-59be9ab81444",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106792911,
          "user_tz": -330,
          "elapsed": 966,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:33:21,538 : INFO : collecting document frequencies\n",
            "2018-05-12 06:33:21,543 : INFO : PROGRESS: processing document #0\n",
            "2018-05-12 06:33:21,546 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "hLFaQj_eJlj0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We used our old corpus from tutorial 1 to initialize (train) the transformation model. Different transformations may require different initialization parameters; in case of   \n",
        "TfIdf, the “training” consists simply of going through the supplied corpus once and computing document frequencies of all its features.  \n",
        "Training other models, such as Latent Semantic Analysis or Latent Dirichlet Allocation, is much more involved and, consequently, takes much more time.\n",
        "\n",
        "> <B>Note</B>:\n",
        "> Transformations always convert between two specific vector spaces. The same vector space (= the same set of feature ids) must be used for training as well as for subsequent vector transformations.  \n",
        "Failure to use the same input feature space, such as   \n",
        "applying a different string preprocessing,   \n",
        "using different feature ids, or  \n",
        "using bag-of-words input vectors where TfIdf vectors are expected,   \n",
        "\n",
        "will result in feature mismatch during transformation calls and consequently in either garbage output and/or runtime exceptions."
      ]
    },
    {
      "metadata": {
        "id": "KvlBtNIzJlj1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1dc7edc-fef4-4f59-a898-e2feeeffdb9a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106871999,
          "user_tz": -330,
          "elapsed": 910,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "doc_bow = [(0, 1), (1, 1)]\n",
        "print(tfidf[doc_bow]) # step 2 -- use the model to transform vectors"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3QeVEWXJlj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Or to apply a transformation to a whole corpus:"
      ]
    },
    {
      "metadata": {
        "id": "3eJaDdcbJlj4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "02a6df4c-15b4-45f6-ec87-1a5b8e7f0a83",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526106897440,
          "user_tz": -330,
          "elapsed": 1134,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "corpus_tfidf = tfidf[corpus]\n",
        "for doc in corpus_tfidf:\n",
        "    print(doc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
            "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
            "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
            "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
            "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
            "[(9, 1.0)]\n",
            "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
            "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
            "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NH9_ODevJlj9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this particular case, we are transforming the same corpus that we used for training, but this is only incidental. Once the transformation model has been initialized, it can be used on any vectors (provided they come from the same vector space, of course else there comes the issue of using different vector notations for the same words),  even if they were not used in the training corpus at all.   \n",
        "\n",
        "This is achieved by a process called folding-in for LSA, by topic inference for LDA etc.\n",
        "\n",
        "> <b>Note:</b> \n",
        "> Calling model[corpus] only creates a wrapper around the old corpus document stream – actual conversions are done on-the-fly, during document iteration. We cannot convert the entire corpus at the time of calling corpus_transformed = model[corpus], because that would mean storing the result in main memory, and that contradicts gensim’s objective of memory-indepedence.  \n",
        "\n",
        "If you will be iterating over the transformed corpus_transformed multiple times, and the transformation is costly, serialize the resulting corpus to disk first and continue using that.\n",
        "\n",
        "Transformations can also be serialized, one on top of another, in a sort of chain:"
      ]
    },
    {
      "metadata": {
        "id": "-9l3JMoJJlj_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "40c230aa-1e68-4cf2-d87e-7a2456f248f7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526107161000,
          "user_tz": -330,
          "elapsed": 954,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
        "# latent semantic indexing...\n",
        "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:39:29,657 : INFO : using serial LSI version on this node\n",
            "2018-05-12 06:39:29,660 : INFO : updating model with new documents\n",
            "2018-05-12 06:39:29,662 : INFO : preparing a new chunk of documents\n",
            "2018-05-12 06:39:29,664 : INFO : using 100 extra samples and 2 power iterations\n",
            "2018-05-12 06:39:29,665 : INFO : 1st phase: constructing (12, 102) action matrix\n",
            "2018-05-12 06:39:29,667 : INFO : orthonormalizing (12, 102) action matrix\n",
            "2018-05-12 06:39:29,670 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
            "2018-05-12 06:39:29,672 : INFO : computing the final decomposition\n",
            "2018-05-12 06:39:29,674 : INFO : keeping 2 factors (discarding 47.565% of energy spectrum)\n",
            "2018-05-12 06:39:29,679 : INFO : processed documents up to #9\n",
            "2018-05-12 06:39:29,680 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
            "2018-05-12 06:39:29,681 : INFO : topic #1(1.476): 0.460*\"system\" + 0.373*\"user\" + 0.332*\"eps\" + 0.328*\"interface\" + 0.320*\"time\" + 0.320*\"response\" + 0.293*\"computer\" + 0.280*\"human\" + 0.171*\"survey\" + -0.161*\"trees\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5VsYQ5zfJlkB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we transformed our Tf-Idf corpus via [Latent Semantic Indexing](http://en.wikipedia.org/wiki/Latent_semantic_indexing) into a latent 2-D space (2-D because we set num_topics=2).   \n",
        "Now you’re probably wondering: what do these two latent dimensions stand for? Let’s inspect with models.LsiModel.print_topics():"
      ]
    },
    {
      "metadata": {
        "id": "gWUFndNbMaWY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1a2afc6a-ce80-4ddf-89cb-a21bccc28c1c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526107177444,
          "user_tz": -330,
          "elapsed": 934,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lsi.print_topics()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:39:46,111 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
            "2018-05-12 06:39:46,113 : INFO : topic #1(1.476): 0.460*\"system\" + 0.373*\"user\" + 0.332*\"eps\" + 0.328*\"interface\" + 0.320*\"time\" + 0.320*\"response\" + 0.293*\"computer\" + 0.280*\"human\" + 0.171*\"survey\" + -0.161*\"trees\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
              " (1,\n",
              "  '0.460*\"system\" + 0.373*\"user\" + 0.332*\"eps\" + 0.328*\"interface\" + 0.320*\"time\" + 0.320*\"response\" + 0.293*\"computer\" + 0.280*\"human\" + 0.171*\"survey\" + -0.161*\"trees\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "IhWFmDNkJlkB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "7e4344fb-6da6-4d79-8ab2-947d488e7758",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526107184546,
          "user_tz": -330,
          "elapsed": 616,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lsi.print_topics(2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:39:53,544 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
            "2018-05-12 06:39:53,546 : INFO : topic #1(1.476): 0.460*\"system\" + 0.373*\"user\" + 0.332*\"eps\" + 0.328*\"interface\" + 0.320*\"time\" + 0.320*\"response\" + 0.293*\"computer\" + 0.280*\"human\" + 0.171*\"survey\" + -0.161*\"trees\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
              " (1,\n",
              "  '0.460*\"system\" + 0.373*\"user\" + 0.332*\"eps\" + 0.328*\"interface\" + 0.320*\"time\" + 0.320*\"response\" + 0.293*\"computer\" + 0.280*\"human\" + 0.171*\"survey\" + -0.161*\"trees\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "nOqqW9eKJlkF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(the topics are printed to log – see the note at the top of this page about activating logging)\n",
        "\n",
        "It appears that according to LSI, “trees”, “graph” and “minors” are all related words (and contribute the most to the direction of the first topic),   \n",
        "\n",
        "while the second topic practically concerns itself with all the other words.  \n",
        "\n",
        "And that is the topic description folks.. :P\n",
        "\n",
        "As expected, the first five documents are more strongly related to the second topic while the remaining four documents to the first topic:"
      ]
    },
    {
      "metadata": {
        "id": "WVPXRMpvJlkG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "52d66f3d-97f4-4701-a3c6-626bf1311aa8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526107186195,
          "user_tz": -330,
          "elapsed": 937,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
        "    print(doc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.0660078339609045), (1, 0.5200703306361854)]\n",
            "[(0, 0.19667592859142574), (1, 0.7609563167700042)]\n",
            "[(0, 0.08992639972446498), (1, 0.7241860626752507)]\n",
            "[(0, 0.07585847652178214), (1, 0.6320551586003428)]\n",
            "[(0, 0.10150299184980191), (1, 0.5737308483002949)]\n",
            "[(0, 0.7032108939378311), (1, -0.16115180214025876)]\n",
            "[(0, 0.877478767311983), (1, -0.16758906864659504)]\n",
            "[(0, 0.9098624686818574), (1, -0.140865536287191)]\n",
            "[(0, 0.6165825350569276), (1, 0.05392907566389325)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZM96WK6WJlkJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "30eb5673-de8a-41cb-bcfb-c93adbd1b26f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526107227185,
          "user_tz": -330,
          "elapsed": 927,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lsi.save(os.path.join(TEMP_FOLDER, 'model.lsi')) # same for tfidf, lda, ...\n",
        "#lsi = models.LsiModel.load(os.path.join(TEMP_FOLDER, 'model.lsi'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:40:35,843 : INFO : saving Projection object under /tmp/model.lsi.projection, separately None\n",
            "2018-05-12 06:40:35,846 : INFO : saved /tmp/model.lsi.projection\n",
            "2018-05-12 06:40:35,847 : INFO : saving LsiModel object under /tmp/model.lsi, separately None\n",
            "2018-05-12 06:40:35,849 : INFO : not storing attribute projection\n",
            "2018-05-12 06:40:35,850 : INFO : not storing attribute dispatcher\n",
            "2018-05-12 06:40:35,851 : INFO : saved /tmp/model.lsi\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "je3P81QkJlkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next question might be: just how exactly similar are those documents to each other? Is there a way to formalize the similarity, so that for a given input document, we can order some other set of documents according to their similarity? Similarity queries are covered in the [next tutorial](https://radimrehurek.com/gensim/tut3.html)."
      ]
    },
    {
      "metadata": {
        "id": "oTREzGi5JlkN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Available transformations\n",
        "\n",
        "Gensim implements several popular Vector Space Model algorithms:\n",
        "\n",
        "### [Term Frequency * Inverse Document Frequency](http://en.wikipedia.org/wiki/Tf–idf) \n",
        "Tf-Idf expects a bag-of-words (integer values) training corpus during initialization. During transformation, it will take a vector and return another vector of the same dimensionality,   \n",
        "\n",
        "*except that features which were rare in the training corpus will have their value increased*.  \n",
        "\n",
        "It therefore converts integer-valued vectors into real-valued ones, while leaving the number of dimensions intact. It can also optionally normalize the resulting vectors to (Euclidean) unit length.  \n",
        "\n",
        "Tf-idf : score of a word... for a document increases with the frequency of the owrd in the document..  \n",
        "and is offset (divided by..? / or some constant and subtracted from) by the frequency of the word in the whole corpus.."
      ]
    },
    {
      "metadata": {
        "id": "btlFw6lIJlkN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "96ae3432-bfdb-44e0-8d4d-99f0f9c875a8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525958318500,
          "user_tz": -330,
          "elapsed": 856,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.TfidfModel(corpus, normalize=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-10 13:18:44,388 : INFO : collecting document frequencies\n",
            "2018-05-10 13:18:44,390 : INFO : PROGRESS: processing document #0\n",
            "2018-05-10 13:18:44,391 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DlQLIWk1JlkQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [Latent Semantic Indexing, LSI (or sometimes LSA)](http://en.wikipedia.org/wiki/Latent_semantic_indexing) \n",
        "LSI transforms documents from either bag-of-words or (preferrably) TfIdf-weighted space into a latent space of a lower dimensionality. For the toy corpus above we used only 2 latent dimensions, but on real corpora, target dimensionality of 200–500 is recommended as a “golden standard” [1].  \n",
        "\n",
        "LSI is based on SVD singular value decomposition..  \n",
        "to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text.   \n",
        "LSI is based on the principle that words that are used in the same contexts tend to have similar meanings.   \n",
        "A key feature of LSI is its ability to extract the conceptual content of a body of text by establishing associations between those terms that occur in similar contexts."
      ]
    },
    {
      "metadata": {
        "id": "YQbgNd3jJlkQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c8919530-1622-4f82-bd1a-237bfea3d29e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526107729545,
          "user_tz": -330,
          "elapsed": 960,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=300)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:48:58,191 : INFO : using serial LSI version on this node\n",
            "2018-05-12 06:48:58,194 : INFO : updating model with new documents\n",
            "2018-05-12 06:48:58,196 : INFO : preparing a new chunk of documents\n",
            "2018-05-12 06:48:58,198 : INFO : using 100 extra samples and 2 power iterations\n",
            "2018-05-12 06:48:58,200 : INFO : 1st phase: constructing (12, 400) action matrix\n",
            "2018-05-12 06:48:58,205 : INFO : orthonormalizing (12, 400) action matrix\n",
            "2018-05-12 06:48:58,213 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
            "2018-05-12 06:48:58,216 : INFO : computing the final decomposition\n",
            "2018-05-12 06:48:58,220 : INFO : keeping 9 factors (discarding 0.000% of energy spectrum)\n",
            "2018-05-12 06:48:58,222 : INFO : processed documents up to #9\n",
            "2018-05-12 06:48:58,224 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
            "2018-05-12 06:48:58,226 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n",
            "2018-05-12 06:48:58,230 : INFO : topic #2(1.191): -0.456*\"response\" + -0.456*\"time\" + 0.352*\"eps\" + 0.340*\"human\" + 0.318*\"interface\" + 0.277*\"system\" + -0.272*\"survey\" + -0.213*\"user\" + 0.183*\"trees\" + -0.114*\"minors\"\n",
            "2018-05-12 06:48:58,236 : INFO : topic #3(1.043): 0.583*\"trees\" + -0.556*\"minors\" + -0.399*\"survey\" + -0.256*\"graph\" + 0.211*\"response\" + 0.211*\"time\" + 0.160*\"user\" + -0.081*\"human\" + -0.038*\"interface\" + -0.035*\"system\"\n",
            "2018-05-12 06:48:58,237 : INFO : topic #4(0.884): 0.611*\"computer\" + -0.425*\"system\" + -0.420*\"eps\" + 0.354*\"interface\" + 0.339*\"human\" + -0.148*\"user\" + -0.058*\"minors\" + 0.047*\"trees\" + -0.034*\"graph\" + 0.027*\"survey\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "W5YArvxTJlkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LSI training is unique in that we can continue “training” at any point, simply by providing more training documents.   \n",
        "This is done by incremental updates to the underlying model, in a process called online training.  \n",
        "Because of this feature, the input document stream may even be infinite – just keep feeding LSI new documents as they arrive, while using the computed transformation model as read-only in the meanwhile!"
      ]
    },
    {
      "metadata": {
        "id": "vWgkAqC_JlkU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> <b>Example</b> \n",
        "> \n",
        "> model.add_documents(another_tfidf_corpus) # now LSI has been trained on tfidf_corpus + another_tfidf_corpus\n",
        "> lsi_vec = model[tfidf_vec] # convert some new document into the LSI space, without affecting the model\n",
        "\n",
        "> model.add_documents(more_documents) # tfidf_corpus + another_tfidf_corpus + more_documents\n",
        "> lsi_vec = model[tfidf_vec]\n"
      ]
    },
    {
      "metadata": {
        "id": "4HPghltGJlkU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "See the [gensim.models.lsimodel](https://radimrehurek.com/gensim/models/lsimodel.html#module-gensim.models.lsimodel) documentation for details on how to make LSI gradually “forget” old observations in infinite streams. If you want to get dirty, there are also parameters you can tweak that affect speed vs. memory footprint vs. numerical precision of the LSI algorithm.\n",
        "\n",
        "gensim uses a novel online incremental streamed distributed training algorithm (quite a mouthful!), which I published in [5]. gensim also executes a stochastic multi-pass algorithm from Halko et al. [4] internally, to accelerate in-core part of the computations. See also \n",
        "    [Experiments on the English Wikipedia](https://radimrehurek.com/gensim/wiki.html) for further speed-ups by distributing the computation across a cluster of computers."
      ]
    },
    {
      "metadata": {
        "id": "zcrnDzmPJlkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [Random Projections](http://www.cis.hut.fi/ella/publications/randproj_kdd.pdf)\n",
        "RP aim to reduce vector space dimensionality.   \n",
        "This is a very efficient (both memory- and CPU-friendly) approach to *approximating TfIdf distances between documents, by throwing in a little randomness*.  \n",
        "Recommended target dimensionality is again in the hundreds/thousands, depending on your dataset."
      ]
    },
    {
      "metadata": {
        "id": "BUFrTPAsJlkW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3e9091c8-d774-4fb2-86af-105ab04a8e41",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526108025544,
          "user_tz": -330,
          "elapsed": 954,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.RpModel(corpus_tfidf, num_topics=500)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:53:54,200 : INFO : no word id mapping provided; initializing from corpus, assuming identity\n",
            "2018-05-12 06:53:54,202 : INFO : constructing (500, 12) random matrix\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0iikLNSjJlka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [Latent Dirichlet Allocation, LDA](http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) \n",
        "LDA is yet another transformation from bag-of-words counts into a topic space of lower dimensionality.(the other one was lsi as above.. )  \n",
        "LDA is a probabilistic extension of LSA(LSA as mentioned above.. is the same as LSI i.e latent semantic indexing a.k.a latent semantic analysis) (also called multinomial PCA), so LDA’s topics can be interpreted as probability distributions over words.   \n",
        "These distributions are, just like with LSA, inferred automatically from a training corpus.   \n",
        "Documents are in turn interpreted as a (soft) mixture of these topics (again, just like with LSA)."
      ]
    },
    {
      "metadata": {
        "id": "-ts_goByJlkb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "cab61358-8fd1-4e84-ed3d-1cb8de75e54b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526108162802,
          "user_tz": -330,
          "elapsed": 959,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.LdaModel(corpus, id2word=dictionary, num_topics=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:56:11,480 : INFO : using symmetric alpha at 0.01\n",
            "2018-05-12 06:56:11,487 : INFO : using symmetric eta at 0.01\n",
            "2018-05-12 06:56:11,491 : INFO : using serial LDA version on this node\n",
            "2018-05-12 06:56:11,493 : INFO : running online (single-pass) LDA training, 100 topics, 1 passes over the supplied corpus of 9 documents, updating model once every 9 documents, evaluating perplexity every 9 documents, iterating 50x with a convergence threshold of 0.001000\n",
            "2018-05-12 06:56:11,496 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "2018-05-12 06:56:11,506 : INFO : -124.650 per-word bound, 33379791051763902422920371088077619200.0 perplexity estimate based on a held-out corpus of 9 documents with 29 words\n",
            "2018-05-12 06:56:11,508 : INFO : PROGRESS: pass 0, at document #9/9\n",
            "2018-05-12 06:56:11,516 : INFO : topic #28 (0.010): 0.083*\"user\" + 0.083*\"system\" + 0.083*\"graph\" + 0.083*\"trees\" + 0.083*\"eps\" + 0.083*\"computer\" + 0.083*\"time\" + 0.083*\"interface\" + 0.083*\"response\" + 0.083*\"human\"\n",
            "2018-05-12 06:56:11,518 : INFO : topic #84 (0.010): 0.083*\"user\" + 0.083*\"system\" + 0.083*\"graph\" + 0.083*\"trees\" + 0.083*\"eps\" + 0.083*\"computer\" + 0.083*\"time\" + 0.083*\"interface\" + 0.083*\"response\" + 0.083*\"human\"\n",
            "2018-05-12 06:56:11,519 : INFO : topic #63 (0.010): 0.083*\"user\" + 0.083*\"system\" + 0.083*\"graph\" + 0.083*\"trees\" + 0.083*\"eps\" + 0.083*\"computer\" + 0.083*\"time\" + 0.083*\"interface\" + 0.083*\"response\" + 0.083*\"human\"\n",
            "2018-05-12 06:56:11,523 : INFO : topic #81 (0.010): 0.083*\"user\" + 0.083*\"system\" + 0.083*\"graph\" + 0.083*\"trees\" + 0.083*\"eps\" + 0.083*\"computer\" + 0.083*\"time\" + 0.083*\"interface\" + 0.083*\"response\" + 0.083*\"human\"\n",
            "2018-05-12 06:56:11,529 : INFO : topic #35 (0.010): 0.083*\"user\" + 0.083*\"system\" + 0.083*\"graph\" + 0.083*\"trees\" + 0.083*\"eps\" + 0.083*\"computer\" + 0.083*\"time\" + 0.083*\"interface\" + 0.083*\"response\" + 0.083*\"human\"\n",
            "2018-05-12 06:56:11,533 : INFO : topic diff=87.393219, rho=1.000000\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P8qwd-CYJlkf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "gensim uses a fast implementation of online LDA parameter estimation based on [2], modified to run in distributed mode on a cluster of computers."
      ]
    },
    {
      "metadata": {
        "id": "b-qcNbvBJlkf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### [Hierarchical Dirichlet Process, HDP](http://jmlr.csail.mit.edu/proceedings/papers/v15/wang11a/wang11a.pdf) \n",
        "HDP is a non-parametric bayesian method (note the missing number of requested topics): (<- gotta check out what this is referring to..)"
      ]
    },
    {
      "metadata": {
        "id": "ca4po8XFJlkg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "68fc12f3-f1d2-4ea3-ae1c-f90b8466fa3d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526108207438,
          "user_tz": -330,
          "elapsed": 950,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.HdpModel(corpus, id2word=dictionary)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-05-12 06:56:56,134 : INFO : (0, '0.478*human + 0.140*minors + 0.126*trees + 0.105*interface + 0.043*response + 0.032*system + 0.029*computer + 0.016*survey + 0.015*user + 0.009*eps')\n",
            "2018-05-12 06:56:56,136 : INFO : (1, '0.293*time + 0.172*response + 0.140*computer + 0.096*user + 0.095*interface + 0.055*graph + 0.043*minors + 0.040*eps + 0.035*survey + 0.017*human')\n",
            "2018-05-12 06:56:56,137 : INFO : (2, '0.343*system + 0.124*time + 0.116*interface + 0.093*graph + 0.073*minors + 0.069*user + 0.066*trees + 0.048*computer + 0.030*eps + 0.018*human')\n",
            "2018-05-12 06:56:56,138 : INFO : (3, '0.343*interface + 0.146*minors + 0.110*graph + 0.105*system + 0.082*trees + 0.067*response + 0.067*computer + 0.041*user + 0.018*human + 0.011*time')\n",
            "2018-05-12 06:56:56,141 : INFO : (4, '0.232*system + 0.190*user + 0.151*interface + 0.126*eps + 0.097*human + 0.082*response + 0.038*computer + 0.036*graph + 0.023*trees + 0.021*time')\n",
            "2018-05-12 06:56:56,145 : INFO : (5, '0.198*eps + 0.180*trees + 0.168*time + 0.128*user + 0.091*response + 0.047*minors + 0.043*survey + 0.042*system + 0.030*computer + 0.028*graph')\n",
            "2018-05-12 06:56:56,147 : INFO : (6, '0.202*time + 0.197*eps + 0.119*interface + 0.107*response + 0.094*computer + 0.082*minors + 0.074*graph + 0.055*human + 0.024*survey + 0.021*system')\n",
            "2018-05-12 06:56:56,148 : INFO : (7, '0.194*eps + 0.184*interface + 0.136*human + 0.112*survey + 0.082*system + 0.078*graph + 0.078*trees + 0.054*computer + 0.041*time + 0.034*user')\n",
            "2018-05-12 06:56:56,150 : INFO : (8, '0.253*eps + 0.222*minors + 0.143*interface + 0.090*human + 0.090*system + 0.062*computer + 0.036*response + 0.031*trees + 0.026*survey + 0.025*graph')\n",
            "2018-05-12 06:56:56,152 : INFO : (9, '0.229*response + 0.181*computer + 0.146*time + 0.121*system + 0.113*human + 0.070*interface + 0.057*eps + 0.034*graph + 0.021*minors + 0.013*survey')\n",
            "2018-05-12 06:56:56,155 : INFO : (10, '0.257*response + 0.182*interface + 0.181*trees + 0.140*human + 0.071*eps + 0.057*computer + 0.035*graph + 0.029*survey + 0.024*system + 0.014*time')\n",
            "2018-05-12 06:56:56,157 : INFO : (11, '0.295*graph + 0.188*interface + 0.114*minors + 0.106*user + 0.101*computer + 0.055*system + 0.042*trees + 0.036*response + 0.026*time + 0.017*human')\n",
            "2018-05-12 06:56:56,160 : INFO : (12, '0.395*system + 0.164*eps + 0.128*survey + 0.097*time + 0.087*user + 0.061*trees + 0.028*interface + 0.017*human + 0.010*graph + 0.008*computer')\n",
            "2018-05-12 06:56:56,161 : INFO : (13, '0.231*trees + 0.173*eps + 0.121*survey + 0.094*time + 0.081*response + 0.065*interface + 0.063*system + 0.062*graph + 0.055*computer + 0.034*user')\n",
            "2018-05-12 06:56:56,164 : INFO : (14, '0.249*eps + 0.177*user + 0.154*time + 0.104*interface + 0.078*trees + 0.073*system + 0.051*computer + 0.038*human + 0.035*survey + 0.018*graph')\n",
            "2018-05-12 06:56:56,166 : INFO : (15, '0.236*system + 0.189*minors + 0.160*trees + 0.108*graph + 0.066*response + 0.058*survey + 0.049*interface + 0.036*time + 0.035*user + 0.028*computer')\n",
            "2018-05-12 06:56:56,169 : INFO : (16, '0.298*eps + 0.162*minors + 0.143*system + 0.087*time + 0.077*computer + 0.070*human + 0.052*user + 0.044*interface + 0.033*trees + 0.023*survey')\n",
            "2018-05-12 06:56:56,171 : INFO : (17, '0.194*survey + 0.152*interface + 0.098*human + 0.088*system + 0.086*eps + 0.085*computer + 0.079*minors + 0.063*time + 0.061*response + 0.048*user')\n",
            "2018-05-12 06:56:56,174 : INFO : (18, '0.184*survey + 0.135*interface + 0.128*user + 0.101*computer + 0.100*trees + 0.098*response + 0.086*minors + 0.054*time + 0.047*human + 0.025*graph')\n",
            "2018-05-12 06:56:56,176 : INFO : (19, '0.210*interface + 0.192*human + 0.138*response + 0.102*trees + 0.091*graph + 0.049*time + 0.047*system + 0.047*user + 0.047*survey + 0.031*eps')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "G_L2bsASJlkj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "gensim uses a fast, online implementation based on [3]. The HDP model is a new addition to gensim, and still rough around its academic edges – use with care."
      ]
    },
    {
      "metadata": {
        "id": "RJUXe3MEJlkk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding new VSM transformations (such as different weighting schemes) is rather trivial; see the API reference or directly the Python code for more info and examples.\n",
        "\n",
        "It is worth repeating that these are all unique, incremental implementations, which do not require the whole training corpus to be present in main memory all at once. With memory taken care of, I am now improving Distributed Computing, to improve CPU efficiency, too. If you feel you could contribute (by testing, providing use-cases or code), please let me know.\n",
        "\n",
        "Continue on to the next tutorial on [Similarity Queries](./Similarity_Queries.ipynb)."
      ]
    },
    {
      "metadata": {
        "id": "4M--JSfIJlkl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "[1]\tBradford. 2008. An empirical study of required dimensionality for large-scale latent semantic indexing applications.  \n",
        "[2]\tHoffman, Blei, Bach. 2010. Online learning for Latent Dirichlet Allocation.  \n",
        "[3]\tWang, Paisley, Blei. 2011. Online variational inference for the hierarchical Dirichlet process.  \n",
        "[4]\tHalko, Martinsson, Tropp. 2009. Finding structure with randomness.  \n",
        "[5]\tŘehůřek. 2011. Subspace tracking for Latent Semantic Analysis.  "
      ]
    },
    {
      "metadata": {
        "id": "l6mOVa25Jlko",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44507bc3-244b-4928-a53c-5350e6e4d349",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526108268398,
          "user_tz": -330,
          "elapsed": 952,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "2+2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}